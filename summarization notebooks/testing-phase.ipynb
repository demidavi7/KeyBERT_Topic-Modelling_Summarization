{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3140615,"sourceType":"datasetVersion","datasetId":1912571}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T16:07:06.761149Z","iopub.execute_input":"2025-01-27T16:07:06.761364Z","iopub.status.idle":"2025-01-27T16:07:10.289939Z","shell.execute_reply.started":"2025-01-27T16:07:06.761346Z","shell.execute_reply":"2025-01-27T16:07:10.289023Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!pip install keybert ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T16:07:10.292066Z","iopub.execute_input":"2025-01-27T16:07:10.292401Z","iopub.status.idle":"2025-01-27T16:07:13.826286Z","shell.execute_reply.started":"2025-01-27T16:07:10.292367Z","shell.execute_reply":"2025-01-27T16:07:13.825266Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: keybert in /usr/local/lib/python3.10/dist-packages (0.8.5)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.26.4)\nRequirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.9.4)\nRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.2.2)\nRequirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from keybert) (3.3.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->keybert) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->keybert) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->keybert) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->keybert) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->keybert) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->keybert) (2.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (4.12.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.47.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.5.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.27.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.4.5)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.5->keybert) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.5->keybert) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->keybert) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.18.5->keybert) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.18.5->keybert) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.12.14)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Utilizing Newsroom ( similar to cnn but not clean pay attention ) ","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd \n# Path to the Newsroom dataset file\ndataset_path = \"/kaggle/input/news-summarization/data.csv\"\n\n# Load the dataset\ndf = pd.read_csv(dataset_path)\n\n# Display the first few rows\ndf.head()\ndf[df['Dataset']=='Multi-News'].sample(100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T16:06:25.143344Z","iopub.execute_input":"2025-01-27T16:06:25.143692Z","iopub.status.idle":"2025-01-27T16:07:06.351647Z","shell.execute_reply.started":"2025-01-27T16:06:25.143667Z","shell.execute_reply":"2025-01-27T16:07:06.350683Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        Unnamed: 0   ID                                            Content  \\\n447992      447992  NaN  Negotiations with nurse Kaci Hickox, who refus...   \n48400        48400  NaN  50 Cent has angered the internet after a video...   \n521616      521616  NaN  A new North Korean propaganda video shows the ...   \n84101        84101  NaN  Google’s robot just got its driver’s license. ...   \n578653      578653  NaN  Tour de France: Mark Cavendish has urine throw...   \n...            ...  ...                                                ...   \n225265      225265  NaN  When an elite crime squad's lead detective (Mi...   \n141702      141702  NaN  Rep. Michele Bachmann has been propelled into ...   \n798856      798856  NaN  JUPITER, Fla. - UPDATE: The Coast Guard held a...   \n378586      378586  NaN  The creators of a dogfighting phone applicatio...   \n522168      522168  NaN  The three women held captive for about a decad...   \n\n                                                  Summary     Dataset  \n447992  – Maine is seeking a court order to force nurs...  Multi-News  \n48400   – 50 Cent is facing outrage and possible legal...  Multi-News  \n521616  – Apparently New York in flames was not enough...  Multi-News  \n84101   – Up until recently, Google's self-driving car...  Multi-News  \n578653  – British bicyclist Mark Cavendish suffered so...  Multi-News  \n...                                                   ...         ...  \n225265  – The Snowman, a film about a detective on the...  Multi-News  \n141702  – A clinic run by Michele Bachmann's therapist...  Multi-News  \n798856  – The boat used by two boys who vanished off t...  Multi-News  \n378586  – Michael Vick is growling about the new \"Dog ...  Multi-News  \n522168  – Two of the three Cleveland captives are home...  Multi-News  \n\n[100 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>Content</th>\n      <th>Summary</th>\n      <th>Dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>447992</th>\n      <td>447992</td>\n      <td>NaN</td>\n      <td>Negotiations with nurse Kaci Hickox, who refus...</td>\n      <td>– Maine is seeking a court order to force nurs...</td>\n      <td>Multi-News</td>\n    </tr>\n    <tr>\n      <th>48400</th>\n      <td>48400</td>\n      <td>NaN</td>\n      <td>50 Cent has angered the internet after a video...</td>\n      <td>– 50 Cent is facing outrage and possible legal...</td>\n      <td>Multi-News</td>\n    </tr>\n    <tr>\n      <th>521616</th>\n      <td>521616</td>\n      <td>NaN</td>\n      <td>A new North Korean propaganda video shows the ...</td>\n      <td>– Apparently New York in flames was not enough...</td>\n      <td>Multi-News</td>\n    </tr>\n    <tr>\n      <th>84101</th>\n      <td>84101</td>\n      <td>NaN</td>\n      <td>Google’s robot just got its driver’s license. ...</td>\n      <td>– Up until recently, Google's self-driving car...</td>\n      <td>Multi-News</td>\n    </tr>\n    <tr>\n      <th>578653</th>\n      <td>578653</td>\n      <td>NaN</td>\n      <td>Tour de France: Mark Cavendish has urine throw...</td>\n      <td>– British bicyclist Mark Cavendish suffered so...</td>\n      <td>Multi-News</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>225265</th>\n      <td>225265</td>\n      <td>NaN</td>\n      <td>When an elite crime squad's lead detective (Mi...</td>\n      <td>– The Snowman, a film about a detective on the...</td>\n      <td>Multi-News</td>\n    </tr>\n    <tr>\n      <th>141702</th>\n      <td>141702</td>\n      <td>NaN</td>\n      <td>Rep. Michele Bachmann has been propelled into ...</td>\n      <td>– A clinic run by Michele Bachmann's therapist...</td>\n      <td>Multi-News</td>\n    </tr>\n    <tr>\n      <th>798856</th>\n      <td>798856</td>\n      <td>NaN</td>\n      <td>JUPITER, Fla. - UPDATE: The Coast Guard held a...</td>\n      <td>– The boat used by two boys who vanished off t...</td>\n      <td>Multi-News</td>\n    </tr>\n    <tr>\n      <th>378586</th>\n      <td>378586</td>\n      <td>NaN</td>\n      <td>The creators of a dogfighting phone applicatio...</td>\n      <td>– Michael Vick is growling about the new \"Dog ...</td>\n      <td>Multi-News</td>\n    </tr>\n    <tr>\n      <th>522168</th>\n      <td>522168</td>\n      <td>NaN</td>\n      <td>The three women held captive for about a decad...</td>\n      <td>– Two of the three Cleveland captives are home...</td>\n      <td>Multi-News</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"dataset = df[df['Dataset']=='Multi-News'].sample(1000)\ndataset.to_csv(\"summarization_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T16:07:06.353009Z","iopub.execute_input":"2025-01-27T16:07:06.353272Z","iopub.status.idle":"2025-01-27T16:07:06.759435Z","shell.execute_reply.started":"2025-01-27T16:07:06.353251Z","shell.execute_reply":"2025-01-27T16:07:06.758497Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Standard fine-tuned model testing ( tested on standard newsroom ) ","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nimport gc\nfrom typing import List, Dict\nfrom tqdm import tqdm\nfrom rouge_score import rouge_scorer\n\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nclass SummarizationPipeline:\n    def __init__(self, \n                 summarization_model_path=\"sshleifer/distilbart-cnn-12-6\",\n                 device=None):\n        self.device = device or torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"Using device: {self.device}\")\n\n        self.tokenizer = AutoTokenizer.from_pretrained(summarization_model_path)\n        self.summarization_model = AutoModelForSeq2SeqLM.from_pretrained(summarization_model_path)\n        self.summarization_model.to(self.device)\n\n        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n\n    def generate_summary(self, text: str, max_length: int = 150) -> str:\n        inputs = self.tokenizer(\n            text, \n            max_length=512, \n            truncation=True, \n            return_tensors=\"pt\"\n        ).to(self.device)\n\n        summary_ids = self.summarization_model.generate(\n            inputs.input_ids, \n            max_length=max_length, \n            num_beams=4, \n            early_stopping=True\n        )\n\n        return self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    def process_dataset(self, \n                        file_path: str, \n                        output_path: str, \n                        batch_size: int = 32,\n                        summary_max_length: int = 512):\n        df = pd.read_csv(file_path)\n        texts = df[\"Content\"].tolist()\n        reference_summaries = df[\"Summary\"].tolist()\n\n        results = []\n        rouge_scores = {\n            'rouge1_precision': [],\n            'rouge1_recall': [],\n            'rouge1_fmeasure': [],\n            'rouge2_precision': [],\n            'rouge2_recall': [],\n            'rouge2_fmeasure': [],\n            'rougeL_precision': [],\n            'rougeL_recall': [],\n            'rougeL_fmeasure': []\n        }\n\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n            batch_texts = texts[i:i + batch_size]\n            batch_references = reference_summaries[i:i + batch_size]\n            \n            for text, ref_summary in zip(batch_texts, batch_references):\n                try:\n                    generated_summary = self.generate_summary(text, summary_max_length)\n                    \n                    # Calculate and store ROUGE scores\n                    score = self.rouge_scorer.score(ref_summary, generated_summary)\n                    \n                    rouge_dict = {\n                        'rouge1_precision': score['rouge1'].precision,\n                        'rouge1_recall': score['rouge1'].recall,\n                        'rouge1_fmeasure': score['rouge1'].fmeasure,\n                        'rouge2_precision': score['rouge2'].precision,\n                        'rouge2_recall': score['rouge2'].recall,\n                        'rouge2_fmeasure': score['rouge2'].fmeasure,\n                        'rougeL_precision': score['rougeL'].precision,\n                        'rougeL_recall': score['rougeL'].recall,\n                        'rougeL_fmeasure': score['rougeL'].fmeasure\n                    }\n                    \n                    results.append({\n                        \"original_text\": text,\n                        \"generated_summary\": generated_summary,\n                        \"reference_summary\": ref_summary,\n                        **rouge_dict\n                    })\n\n                    # Accumulate scores for total metrics\n                    for metric, value in rouge_dict.items():\n                        rouge_scores[metric].append(value)\n\n                except Exception as e:\n                    print(f\"Error processing text: {e}\")\n\n            # Memory management\n            if self.device.type == 'cuda':\n                torch.cuda.empty_cache()\n                gc.collect()\n\n        # Calculate total ROUGE metrics\n        total_metrics = {\n            metric: np.mean(scores) for metric, scores in rouge_scores.items()\n        }\n\n        # Save results to CSV\n        results_df = pd.DataFrame(results)\n        results_df.to_csv(output_path, index=False)\n        \n        # Save total metrics to a separate file\n        with open(output_path.replace('.csv', '_metrics.txt'), 'w') as f:\n            f.write(\"Total ROUGE Metrics:\\n\")\n            for metric, value in total_metrics.items():\n                f.write(f\"{metric}: {value:.4f}\\n\")\n\n        print(\"Total ROUGE Metrics:\")\n        for metric, value in total_metrics.items():\n            print(f\"{metric}: {value:.4f}\")\n\n        print(f\"Processed {len(results)} documents. Results saved to {output_path}\")\n\ndef main():\n    pipeline = SummarizationPipeline()\n    pipeline.process_dataset(\n        file_path=\"summarization_dataset.csv\",\n        output_path=\"summarization_results_no_keywords.csv\",\n        batch_size=32,\n        summary_max_length= 1024\n    )\n\nif __name__ == '__main__':\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T16:07:13.827458Z","iopub.execute_input":"2025-01-27T16:07:13.827707Z","iopub.status.idle":"2025-01-27T16:18:52.692125Z","shell.execute_reply.started":"2025-01-27T16:07:13.827678Z","shell.execute_reply":"2025-01-27T16:18:52.691305Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda:0\n","output_type":"stream"},{"name":"stderr","text":"Processing batches: 100%|██████████| 32/32 [11:36<00:00, 21.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"Total ROUGE Metrics:\nrouge1_precision: 0.6081\nrouge1_recall: 0.1735\nrouge1_fmeasure: 0.2629\nrouge2_precision: 0.2070\nrouge2_recall: 0.0581\nrouge2_fmeasure: 0.0885\nrougeL_precision: 0.3612\nrougeL_recall: 0.1025\nrougeL_fmeasure: 0.1555\nProcessed 1000 documents. Results saved to summarization_results_no_keywords.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Top keyword fine-tuned model testing ( tested on enriched newsroom ) ","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nimport gc\nfrom typing import List, Dict\nfrom tqdm import tqdm\nfrom rouge_score import rouge_scorer\n\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom keybert import KeyBERT\nfrom sentence_transformers import SentenceTransformer\n\nclass SummarizationPipeline:\n    def __init__(self, \n                 keyword_model_path=\"all-MiniLM-L6-v2\", \n                 summarization_model_path=\"VexPoli/distilbart-summarization-top-o1\",\n                 device=None):\n        self.device = device or torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"Using device: {self.device}\")\n\n        self.keyword_model = SentenceTransformer(keyword_model_path)\n        if self.device.type == 'cuda':\n            self.keyword_model.half()\n        self.keyword_model.to(self.device)\n        self.kw_model = KeyBERT(model=self.keyword_model)\n\n        self.tokenizer = AutoTokenizer.from_pretrained(summarization_model_path)\n        self.summarization_model = AutoModelForSeq2SeqLM.from_pretrained(summarization_model_path)\n        self.summarization_model.to(self.device)\n\n        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n\n    def extract_keywords(self, text: str, top_n: int = 10) -> str:\n        keywords = self.kw_model.extract_keywords(\n            text,\n            keyphrase_ngram_range=(1, 2),\n            stop_words='english',\n            top_n=top_n,\n            use_maxsum=False,\n            use_mmr=True,\n            diversity=0.5\n        )\n        return \", \".join([f\"<keyword>{kw.upper()}</keyword>\" for kw, score in keywords])\n\n    def enrich_text(self, text: str, top_n_keywords: int = 10) -> str:\n        formatted_keywords = self.extract_keywords(text, top_n_keywords)\n        return f\"Keywords: {formatted_keywords}\\n\\n{text}\"\n\n    def generate_summary(self, enriched_text: str, max_length: int = 150) -> str:\n        inputs = self.tokenizer(\n            enriched_text, \n            max_length=512, \n            truncation=True, \n            return_tensors=\"pt\"\n        ).to(self.device)\n\n        summary_ids = self.summarization_model.generate(\n            inputs.input_ids, \n            max_length=max_length, \n            num_beams=4, \n            early_stopping=True\n        )\n\n        return self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    def process_dataset(self, \n                        file_path: str, \n                        output_path: str, \n                        batch_size: int = 32, \n                        top_n_keywords: int = 10,\n                        summary_max_length: int = 512):\n        df = pd.read_csv(file_path)\n        texts = df[\"Content\"].tolist()\n        reference_summaries = df[\"Summary\"].tolist()\n\n        results = []\n        rouge_scores = {\n            'rouge1_precision': [],\n            'rouge1_recall': [],\n            'rouge1_fmeasure': [],\n            'rouge2_precision': [],\n            'rouge2_recall': [],\n            'rouge2_fmeasure': [],\n            'rougeL_precision': [],\n            'rougeL_recall': [],\n            'rougeL_fmeasure': []\n        }\n\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n            batch_texts = texts[i:i + batch_size]\n            batch_references = reference_summaries[i:i + batch_size]\n            \n            for text, ref_summary in zip(batch_texts, batch_references):\n                try:\n                    enriched_text = self.enrich_text(text, top_n_keywords)\n                    generated_summary = self.generate_summary(enriched_text, summary_max_length)\n                    \n                    # Calculate and store ROUGE scores\n                    score = self.rouge_scorer.score(ref_summary, generated_summary)\n                    \n                    rouge_dict = {\n                        'rouge1_precision': score['rouge1'].precision,\n                        'rouge1_recall': score['rouge1'].recall,\n                        'rouge1_fmeasure': score['rouge1'].fmeasure,\n                        'rouge2_precision': score['rouge2'].precision,\n                        'rouge2_recall': score['rouge2'].recall,\n                        'rouge2_fmeasure': score['rouge2'].fmeasure,\n                        'rougeL_precision': score['rougeL'].precision,\n                        'rougeL_recall': score['rougeL'].recall,\n                        'rougeL_fmeasure': score['rougeL'].fmeasure\n                    }\n                    \n                    results.append({\n                        \"original_text\": text,\n                        \"enriched_text\": enriched_text,\n                        \"generated_summary\": generated_summary,\n                        \"reference_summary\": ref_summary,\n                        **rouge_dict\n                    })\n\n                    # Accumulate scores for total metrics\n                    for metric, value in rouge_dict.items():\n                        rouge_scores[metric].append(value)\n\n                except Exception as e:\n                    print(f\"Error processing text: {e}\")\n\n            # Memory management\n            if self.device.type == 'cuda':\n                torch.cuda.empty_cache()\n                gc.collect()\n\n        # Calculate total ROUGE metrics\n        total_metrics = {\n            metric: np.mean(scores) for metric, scores in rouge_scores.items()\n        }\n\n        # Save results to CSV\n        results_df = pd.DataFrame(results)\n        results_df.to_csv(output_path, index=False)\n        \n        # Save total metrics to a separate file\n        with open(output_path.replace('.csv', '_metrics.txt'), 'w') as f:\n            f.write(\"Total ROUGE Metrics:\\n\")\n            for metric, value in total_metrics.items():\n                f.write(f\"{metric}: {value:.4f}\\n\")\n\n        print(\"Total ROUGE Metrics:\")\n        for metric, value in total_metrics.items():\n            print(f\"{metric}: {value:.4f}\")\n\n        print(f\"Processed {len(results)} documents. Results saved to {output_path}\")\n\ndef main():\n    pipeline = SummarizationPipeline()\n    pipeline.process_dataset(\n        file_path=\"summarization_dataset.csv\",\n        output_path=\"summarization_results.csv\",\n        batch_size=32,\n        top_n_keywords=10,\n        summary_max_length=1024\n    )\n\nif __name__ == '__main__':\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T16:18:52.708396Z","iopub.execute_input":"2025-01-27T16:18:52.708638Z","iopub.status.idle":"2025-01-27T16:33:11.899472Z","shell.execute_reply.started":"2025-01-27T16:18:52.708619Z","shell.execute_reply":"2025-01-27T16:33:11.898602Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda:0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n  warnings.warn(\nProcessing batches: 100%|██████████| 32/32 [14:15<00:00, 26.73s/it]\n","output_type":"stream"},{"name":"stdout","text":"Total ROUGE Metrics:\nrouge1_precision: 0.6230\nrouge1_recall: 0.1245\nrouge1_fmeasure: 0.2017\nrouge2_precision: 0.2173\nrouge2_recall: 0.0423\nrouge2_fmeasure: 0.0688\nrougeL_precision: 0.3993\nrougeL_recall: 0.0786\nrougeL_fmeasure: 0.1276\nProcessed 1000 documents. Results saved to summarization_results.csv\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Down keywords fine-tuned model  testing  ( tested on enriched newsroom ) ","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nimport gc\nfrom typing import List, Dict\nfrom tqdm import tqdm\nfrom rouge_score import rouge_scorer\n\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom keybert import KeyBERT\nfrom sentence_transformers import SentenceTransformer\n\nclass SummarizationPipeline:\n    def __init__(self, \n                 keyword_model_path=\"all-MiniLM-L6-v2\", \n                 summarization_model_path=\"VexPoli/distilbart-summarization-down-o1\",\n                 device=None):\n        self.device = device or torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"Using device: {self.device}\")\n\n        self.keyword_model = SentenceTransformer(keyword_model_path)\n        if self.device.type == 'cuda':\n            self.keyword_model.half()\n        self.keyword_model.to(self.device)\n        self.kw_model = KeyBERT(model=self.keyword_model)\n\n        self.tokenizer = AutoTokenizer.from_pretrained(summarization_model_path)\n        self.summarization_model = AutoModelForSeq2SeqLM.from_pretrained(summarization_model_path)\n        self.summarization_model.to(self.device)\n\n        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n\n    def extract_keywords(self, text: str, top_n: int = 10) -> str:\n        keywords = self.kw_model.extract_keywords(\n            text,\n            keyphrase_ngram_range=(1, 2),\n            stop_words='english',\n            top_n=top_n,\n            use_maxsum=False,\n            use_mmr=True,\n            diversity=0.5\n        )\n        return \", \".join([f\"<keyword>{kw.upper()}</keyword>\" for kw, score in keywords])\n\n    def enrich_text(self, text: str, top_n_keywords: int = 10) -> str:\n        formatted_keywords = self.extract_keywords(text, top_n_keywords)\n        return f\"Keywords: {text}\\n\\n{formatted_keywords}\"\n\n    def generate_summary(self, enriched_text: str, max_length: int = 150) -> str:\n        inputs = self.tokenizer(\n            enriched_text, \n            max_length=512, \n            truncation=True, \n            return_tensors=\"pt\"\n        ).to(self.device)\n\n        summary_ids = self.summarization_model.generate(\n            inputs.input_ids, \n            max_length=max_length, \n            num_beams=4, \n            early_stopping=True\n        )\n\n        return self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    def process_dataset(self, \n                        file_path: str, \n                        output_path: str, \n                        batch_size: int = 32, \n                        top_n_keywords: int = 10,\n                        summary_max_length: int = 512):\n        df = pd.read_csv(file_path)\n        texts = df[\"Content\"].tolist()\n        reference_summaries = df[\"Summary\"].tolist()\n\n        results = []\n        rouge_scores = {\n            'rouge1_precision': [],\n            'rouge1_recall': [],\n            'rouge1_fmeasure': [],\n            'rouge2_precision': [],\n            'rouge2_recall': [],\n            'rouge2_fmeasure': [],\n            'rougeL_precision': [],\n            'rougeL_recall': [],\n            'rougeL_fmeasure': []\n        }\n\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n            batch_texts = texts[i:i + batch_size]\n            batch_references = reference_summaries[i:i + batch_size]\n            \n            for text, ref_summary in zip(batch_texts, batch_references):\n                try:\n                    enriched_text = self.enrich_text(text, top_n_keywords)\n                    generated_summary = self.generate_summary(enriched_text, summary_max_length)\n                    \n                    # Calculate and store ROUGE scores\n                    score = self.rouge_scorer.score(ref_summary, generated_summary)\n                    \n                    rouge_dict = {\n                        'rouge1_precision': score['rouge1'].precision,\n                        'rouge1_recall': score['rouge1'].recall,\n                        'rouge1_fmeasure': score['rouge1'].fmeasure,\n                        'rouge2_precision': score['rouge2'].precision,\n                        'rouge2_recall': score['rouge2'].recall,\n                        'rouge2_fmeasure': score['rouge2'].fmeasure,\n                        'rougeL_precision': score['rougeL'].precision,\n                        'rougeL_recall': score['rougeL'].recall,\n                        'rougeL_fmeasure': score['rougeL'].fmeasure\n                    }\n                    \n                    results.append({\n                        \"original_text\": text,\n                        \"enriched_text\": enriched_text,\n                        \"generated_summary\": generated_summary,\n                        \"reference_summary\": ref_summary,\n                        **rouge_dict\n                    })\n\n                    # Accumulate scores for total metrics\n                    for metric, value in rouge_dict.items():\n                        rouge_scores[metric].append(value)\n\n                except Exception as e:\n                    print(f\"Error processing text: {e}\")\n\n            # Memory management\n            if self.device.type == 'cuda':\n                torch.cuda.empty_cache()\n                gc.collect()\n\n        # Calculate total ROUGE metrics\n        total_metrics = {\n            metric: np.mean(scores) for metric, scores in rouge_scores.items()\n        }\n\n        # Save results to CSV\n        results_df = pd.DataFrame(results)\n        results_df.to_csv(output_path, index=False)\n        \n        # Save total metrics to a separate file\n        with open(output_path.replace('.csv', '_metrics.txt'), 'w') as f:\n            f.write(\"Total ROUGE Metrics:\\n\")\n            for metric, value in total_metrics.items():\n                f.write(f\"{metric}: {value:.4f}\\n\")\n\n        print(\"Total ROUGE Metrics:\")\n        for metric, value in total_metrics.items():\n            print(f\"{metric}: {value:.4f}\")\n\n        print(f\"Processed {len(results)} documents. Results saved to {output_path}\")\n\ndef main():\n    pipeline = SummarizationPipeline()\n    pipeline.process_dataset(\n        file_path=\"summarization_dataset.csv\",\n        output_path=\"summarization_results.csv\",\n        batch_size=32,\n        top_n_keywords=10,\n        summary_max_length=1024\n    )\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T16:33:11.905425Z","iopub.execute_input":"2025-01-27T16:33:11.905671Z","iopub.status.idle":"2025-01-27T16:47:50.403594Z","shell.execute_reply.started":"2025-01-27T16:33:11.905651Z","shell.execute_reply":"2025-01-27T16:47:50.402635Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda:0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n  warnings.warn(\nProcessing batches: 100%|██████████| 32/32 [14:34<00:00, 27.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"Total ROUGE Metrics:\nrouge1_precision: 0.6227\nrouge1_recall: 0.1281\nrouge1_fmeasure: 0.2073\nrouge2_precision: 0.2172\nrouge2_recall: 0.0437\nrouge2_fmeasure: 0.0710\nrougeL_precision: 0.3967\nrougeL_recall: 0.0808\nrougeL_fmeasure: 0.1310\nProcessed 1000 documents. Results saved to summarization_results.csv\n","output_type":"stream"}],"execution_count":21}]}